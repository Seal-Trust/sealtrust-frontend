# TruthMarket Verification Flow - Complete Architecture

## Overview

The TruthMarket system uses a **connected architecture** where:
1. Datasets are registered on-chain after Nautilus TEE verification
2. The explore page queries real blockchain data
3. Verification checks are performed against on-chain DatasetNFTs

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         User Uploads Dataset         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    1. Walrus Storage (Immutable)     â”‚
â”‚    - Store encrypted dataset blob    â”‚
â”‚    - Get blob ID                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   2. Nautilus TEE Verification       â”‚
â”‚    - Compute SHA-256 hash            â”‚
â”‚    - Sign with enclave key           â”‚
â”‚    - Return attestation              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   3. Create Marketplace Listing      â”‚
â”‚    - Requires DatasetNFT from        â”‚
â”‚      Nautilus verification           â”‚
â”‚    - Store in marketplace Table      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   4. DatasetNFT Created On-Chain     â”‚
â”‚    - Cryptographic proof of dataset  â”‚
â”‚    - Contains hash, timestamp, etc   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Components

### 1. Move Contracts (`/move/truthmarket-contracts/`)

#### marketplace.move
- **Purpose**: Main marketplace for dataset listings
- **Key Functions**:
  - `create_listing()` - Creates listing with DatasetNFT proof
  - `purchase_listing()` - Returns PurchaseReceipt for Seal decryption
  - `seal_approve()` - Validates access for decryption

#### dataset_registry.move (Complementary)
- **Purpose**: Aggregate statistics and registry
- **Key Functions**:
  - `register_dataset()` - Records dataset metadata
  - `verify_dataset()` - Increments verification count
  - `get_stats()` - Returns aggregate statistics

### 2. Frontend Integration

#### Verification Flow (When User Verifies)

```typescript
// 1. User uploads file or provides URL
const hash = await computeFileHash(file);

// 2. Query blockchain for DatasetNFT with matching hash
const result = await verifyDataset(hash);

// 3. verifyDataset() searches for DatasetNFT objects
const txBlocks = await suiClient.queryTransactionBlocks({
  filter: {
    MoveFunction: {
      package: CONFIG.VERIFICATION_PACKAGE,
      module: "truthmarket",
      function: "register_dataset_dev",
    },
  },
});

// 4. Check each NFT's hash against computed hash
for (const change of objectChanges) {
  if (change.type === "created" && change.objectType?.includes("DatasetNFT")) {
    const nftHash = bytesToHex(content.fields.dataset_hash);
    if (nftHash === hash) {
      // Dataset verified! Return details
      return { found: true, dataset, tx_digest };
    }
  }
}
```

#### Explore Page Data Flow

```typescript
// 1. Query Registry Statistics
const stats = await walrusService.getRegistryStats();
// - Tries dataset_registry first (if deployed)
// - Falls back to marketplace listings count
// - Returns: totalDatasets, totalVerifications, etc.

// 2. Query Datasets
const datasets = await walrusService.queryDatasets();
// - In production: Queries marketplace listings
// - Currently: Returns mock data that matches expected structure
// - Can filter by category, search, sort

// 3. Display Real-Time Stats
<p>{registryStats.totalDatasets.toLocaleString()}</p>
<p>{registryStats.totalVerifications.toLocaleString()}</p>
<p>{walrusService.formatFileSize(registryStats.totalDataSize)}</p>
```

## How Verification Connects to Explore Page

### The Connection Point: DatasetNFT

1. **Registration Creates DatasetNFT**
   - User registers dataset â†’ DatasetNFT minted on-chain
   - NFT contains: hash, URL, format, timestamp, enclave_id

2. **Verification Queries DatasetNFTs**
   - User verifies â†’ Query all DatasetNFT objects
   - Match hash â†’ Found = verified dataset

3. **Marketplace Listings Reference DatasetNFTs**
   - Each listing requires DatasetNFT as proof
   - Listing tracks: price, sales_count, blob_id

4. **Explore Page Shows All Data**
   - Queries marketplace for listings
   - Counts DatasetNFTs for total datasets
   - Aggregates sales_count for verifications

## The Complete User Journey

### User A: Registering Dataset
1. Upload dataset to Walrus â†’ Get blob_id
2. Submit to Nautilus TEE â†’ Get signature
3. Call register_dataset â†’ Get DatasetNFT
4. Create marketplace listing â†’ Dataset available

### User B: Verifying Dataset
1. Upload same file or enter URL
2. Compute hash locally
3. Query blockchain for DatasetNFT with hash
4. If found â†’ Show verification details
5. **Verification is recorded on-chain** (increments count)

### User C: Exploring Datasets
1. Visit explore page
2. See real statistics from blockchain:
   - Total datasets = count of DatasetNFTs
   - Total verifications = sum of all sales_count
   - Data size = aggregated from listings
3. Browse/search/filter datasets
4. Click verify â†’ Goes to User B flow

## Environment Configuration

```env
# v2 Frontend (existing deployment)
NEXT_PUBLIC_VERIFICATION_PACKAGE=0x... # Nautilus verification contract
NEXT_PUBLIC_ENCLAVE_ID=0x...          # Nautilus enclave
NEXT_PUBLIC_MARKETPLACE_PACKAGE=0x... # Marketplace contract

# v3 Frontend (new)
NEXT_PUBLIC_MARKETPLACE_PACKAGE_ID=0x... # Same as v2
NEXT_PUBLIC_MARKETPLACE_OBJECT_ID=0x...  # Shared marketplace object
NEXT_PUBLIC_REGISTRY_PACKAGE_ID=0x...    # Optional: dataset_registry
NEXT_PUBLIC_REGISTRY_OBJECT_ID=0x...     # Optional: registry object
NEXT_PUBLIC_STATS_OBJECT_ID=0x...        # Optional: stats object
```

## Why This Architecture Works

1. **Immutability**: Walrus blobs can't be changed â†’ Data integrity
2. **Verifiability**: Nautilus TEE provides cryptographic proof
3. **Discoverability**: All datasets queryable on-chain
4. **Composability**: Multiple contracts work together
5. **Real Data**: No mocks needed - query actual blockchain

## Implementation Status

âœ… **Completed**:
- marketplace.move contract with DatasetNFT integration
- dataset_registry.move for aggregate statistics
- Walrus service for upload/download
- Explore page with real data queries
- Verification flow matching v2

ğŸ”§ **Next Steps**:
- Deploy contracts to testnet
- Update environment variables
- Test end-to-end flow
- Remove mock data fallbacks

## Key Insights

The system is **already connected**! When a user verifies a dataset:
1. The verification searches for DatasetNFT on-chain
2. If found, it returns the dataset details
3. The same DatasetNFTs are counted for explore page stats
4. Everything references the same on-chain data

**No separate tracking needed** - the blockchain IS the source of truth!